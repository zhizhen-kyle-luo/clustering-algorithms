{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68bfbecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openalexapi\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import time\n",
    "import math\n",
    "# Getting all author ids through search of first and last name:\n",
    "base_url = 'https://api.openalex.org/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2370ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds all author ids given name\n",
    "#%%time\n",
    "def get_authorIDs(name):\n",
    "    setofIDs = set()\n",
    "    page = 1\n",
    "    visualize_data = {}  # Initialize with an empty dictionary\n",
    "    \n",
    "    while True:\n",
    "        full_query = f'https://api.openalex.org/authors?search={name}&page={page}'\n",
    "        response = requests.get(full_query)\n",
    "        visualize_data = response.json()\n",
    "        \n",
    "        for result in visualize_data['results']:\n",
    "            openalex_id = result['id'].replace(\"https://openalex.org/\", \"\")\n",
    "            setofIDs.add(openalex_id)\n",
    "        \n",
    "        page += 1\n",
    "        if page > math.ceil(visualize_data['meta']['count'] / 25):\n",
    "            break\n",
    "\n",
    "    print(f'There are {len(setofIDs)} author ids for {name}')\n",
    "    return setofIDs\n",
    "\n",
    "#get_authorIDs(\"Freddy Nguyen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa658ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finds all work ids given author ids\n",
    "def work_id(givenAuthorID):\n",
    "    filtered_works_url = f'https://api.openalex.org/works?filter=author.id:{givenAuthorID}&page='\n",
    "    page = 1\n",
    "    all_worksID = []\n",
    "\n",
    "    # Loop through pages\n",
    "    while True:\n",
    "        # Request page from OpenAlex\n",
    "        url = filtered_works_url + str(page)\n",
    "        page_with_results = requests.get(url).json()\n",
    "        results = page_with_results['results']\n",
    "        \n",
    "        # Append work IDs using list comprehension\n",
    "        all_worksID.extend([work['id'].replace(\"https://openalex.org/\", \"\") for work in results])\n",
    "        \n",
    "        # Check if there are more pages\n",
    "        if len(results) != page_with_results['meta']['per_page']:\n",
    "            break\n",
    "        \n",
    "        # Next page\n",
    "        page += 1\n",
    "\n",
    "    #print(f'There are {len(all_worksID)} works for {givenAuthorID}')\n",
    "    return all_worksID\n",
    "\n",
    "#work_id('A2118799503')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bc3b61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finds entire work summary given work id\n",
    "def findWork(workId):\n",
    "    fullquery = base_url + 'works/' + workId\n",
    "    response = requests.get(fullquery)\n",
    "    visualize_data = response.json()\n",
    "\n",
    "    # Remove multiple keys using a dictionary comprehension\n",
    "    keys_to_remove = [\"abstract_inverted_index\", \"related_works\", \"ngrams_url\"]\n",
    "    visualize_data = {key: visualize_data[key] for key in visualize_data if key not in keys_to_remove}\n",
    "\n",
    "    return visualize_data\n",
    "#findWork('W1986121817')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb9eb097",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finds all work titles given name\n",
    "def findAllTitles(name):\n",
    "    count = 0\n",
    "    final = {}\n",
    "    aIDs = get_authorIDs(name)\n",
    "    \n",
    "    for i in aIDs:\n",
    "        temp = {}\n",
    "        wIDs = work_id(i)\n",
    "        for i2 in wIDs:\n",
    "            allinfo = findWork(i2)\n",
    "            for concept in allinfo['authorships']:\n",
    "                firstDict = concept['author']\n",
    "                nameIn = firstDict['display_name'].lower()\n",
    "                if name.lower()==nameIn.lower():\n",
    "                    temp[i2]=allinfo['title']\n",
    "        final[i]=temp\n",
    "    return final\n",
    "#findAllTitles(\"Freddy Nguyen\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d034d9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finds all work concepts given author id\n",
    "def findWorkConcepts(aID):  \n",
    "    finalWorkSet = set()\n",
    "    workIds = work_id(aID)\n",
    "    for wID in workIds:\n",
    "        allinfo = findWork(wID)\n",
    "        for concept in allinfo['concepts']:\n",
    "            if float(concept['score']) >= 0.3 and float(concept['level']) >= 1:\n",
    "                finalWorkSet.add(concept['display_name'].lower())\n",
    "    return finalWorkSet\n",
    "#findWorkConcepts('A4344140327')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15b4b028",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find institution given author id\n",
    "def findAuthorInstitutions(aID):\n",
    "    full_query = f'https://api.openalex.org/authors/{aID}'\n",
    "    response = requests.get(full_query)\n",
    "    visualize_data = response.json()\n",
    "    \n",
    "    # Use a ternary operator for conditional return\n",
    "    return visualize_data[\"last_known_institution\"][\"display_name\"] if visualize_data[\"last_known_institution\"] is not None else None\n",
    "\n",
    "#findAuthorInstitutions('A4334433008')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bcebe3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Incipian LLC'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finds work institutions given author id and name\n",
    "def findWorkInstitutions(i, name):  \n",
    "    finalSet = set()\n",
    "    workIds = work_id(i)\n",
    "    for wID in workIds:\n",
    "        allinfo = findWork(wID)\n",
    "        for item2 in allinfo['authorships']:\n",
    "            item3 = item2['author']\n",
    "            fixedName = item3['display_name']\n",
    "            if fixedName!= None:\n",
    "                partName = item3['display_name'].split()\n",
    "                if len(partName)==3:\n",
    "                    del partName[1]\n",
    "                    fixedName = \" \".join(partName)\n",
    "                if fixedName==name:\n",
    "                    for item3 in item2[\"institutions\"]:\n",
    "                        finalSet.add(item3['display_name'])\n",
    "                \n",
    "    return finalSet\n",
    "findWorkInstitutions('A4366268973', \"Joon You\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9aa6ccb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finds coAuthors of all works given author id\n",
    "#%%time\n",
    "def findCoAuthors(aID):\n",
    "    totalCoAuthors = set()\n",
    "    for wID in work_id(aID):\n",
    "        allinfo = findWork(wID)\n",
    "        for concept in allinfo['authorships']:\n",
    "            firstDict = concept['author']\n",
    "            if firstDict['display_name'] != None:\n",
    "                name = firstDict['display_name'].lower()\n",
    "                parts = name.split()\n",
    "                if len(parts)==3:\n",
    "                    del parts[1]\n",
    "                    name = \" \".join(parts)\n",
    "                totalCoAuthors.add(name)\n",
    "    return totalCoAuthors\n",
    "\n",
    "#findCoAuthors('A4350360547')       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1ab04e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scores(value1, value2, listFilter):\n",
    "    try:\n",
    "        final_scores = []\n",
    "        for v1, v2, v3 in zip(value1, value2, listFilter):\n",
    "            score = 0\n",
    "            if v1 is not None and v2 is not None:\n",
    "                if isinstance(v1, set) and isinstance(v2, set) and len(v1.intersection(v2))>=1:\n",
    "                    intersection = len(v1.intersection(v2))\n",
    "                    if v3 == \"institution\" and intersection > 1:\n",
    "                        score = 0.3  \n",
    "                    elif v3 == \"institution\" and intersection == 1:\n",
    "                        score = 0.2\n",
    "                    elif v3 == \"concept\" or v3 == \"coauthor\":\n",
    "                        score = (intersection/len(v1)) + (intersection/len(v2)) #2 is 100% same list (threshold < 0.3)\n",
    "            final_scores.append(score)\n",
    "        \n",
    "        total = sum(final_scores)\n",
    "        return total\n",
    "    \n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "    \n",
    "scores([{'Massachusetts Institute of Technology', \"MIT\"}],\n",
    "       [{'Massachusetts Institute of Technology', \"MIT\"}], [\"institution\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "122fed6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combination(name, listFilter):\n",
    "    totalDict = {}\n",
    "    removeIds = set()\n",
    "    ids = get_authorIDs(name)\n",
    "    for i in ids:\n",
    "        indvList = []\n",
    "        for var in listFilter:\n",
    "            if var.lower() == \"institution\":\n",
    "                indvList.append(findWorkInstitutions(i,name))\n",
    "            elif var.lower() == \"concept\":\n",
    "                indvList.append(findWorkConcepts(i))\n",
    "            elif var.lower() == \"coauthor\":\n",
    "                coauthors = findCoAuthors(i)\n",
    "                if name.lower() not in coauthors:\n",
    "                    print(f'THERE IS NO {name} IN SET FOR {i}')\n",
    "                    removeIds.add(i)\n",
    "                else:\n",
    "                    coauthors.discard(name.lower())\n",
    "                indvList.append(coauthors)\n",
    "        totalDict[i] = indvList\n",
    "    for i2 in removeIds:\n",
    "        totalDict.pop(i2)\n",
    "    print(f'THERE ARE {len(totalDict.keys())} KEYS LEFT SINCE {len(removeIds)} IDS DID NOT HAVE {name} IN AUTHORSHIPS')\n",
    "    return totalDict\n",
    "\n",
    "#combination2(\"Freddy Nguyen\", [\"institution\", \"coauthor\",\"concept\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2505d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def finalMerge(name, listFilter):\n",
    "    dictGiven = combination(name, listFilter)\n",
    "    print(f'Starting with {len(dictGiven)} ids')\n",
    "    finalDict = {}\n",
    "    removeKeys = set()\n",
    "    for key, value in dictGiven.items():\n",
    "        tempSet = set()\n",
    "        for key2, value2 in dictGiven.items():\n",
    "            if key != key2:\n",
    "                numCheck = scores(value, value2, listFilter)  # Use the correct function name \"scores\"\n",
    "                if round(numCheck, ndigits=1) >= 0.3: \n",
    "                    tempSet.add((key2))\n",
    "                    removeKeys.add(key2)\n",
    "        finalDict[key] = tempSet\n",
    "        \n",
    "        \n",
    "    \n",
    "    mergedValues = set()\n",
    "    duplicates = set()\n",
    "    delete = set()\n",
    "    finalDict2 = dict(finalDict)\n",
    "    \n",
    "    for key1, value1 in finalDict.items():\n",
    "        for key2, value2 in finalDict.items():\n",
    "            \n",
    "            if key1 != key2 and len(value1) > 0 and len(value2) > 0:\n",
    "                tempSet1 = set(value1)\n",
    "                tempSet1.add(key1)\n",
    "                tempSet2 = set(value2)\n",
    "                tempSet2.add(key2)\n",
    "                \n",
    "            \n",
    "                if len(tempSet1.intersection(tempSet2))> 0 and key1 not in duplicates and key2 not in duplicates:    \n",
    "                    if key1 in finalDict2[key2]:\n",
    "                        finalDict2[key2].remove(key1)\n",
    "                    if key1 in tempSet2:\n",
    "                        tempSet2.remove(key1)\n",
    "                    finalDict2[key1] = finalDict2[key1] | tempSet2\n",
    "                    duplicates.add(key2)\n",
    "                    del finalDict2[key2]\n",
    "                    delete = delete | (value2)\n",
    "                    \n",
    "    for i in delete:\n",
    "        if i in finalDict2.keys():\n",
    "            del finalDict2[i]\n",
    "    \n",
    "    print(f'Ending with {len(finalDict2.keys())} ids')\n",
    "    \n",
    "    return finalDict2\n",
    "    \n",
    "#finalMerge(\"Joon You\", [\"institution\", \"coauthor\",\"concept\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc40d8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 33 author ids for Ami Bhatt\n",
      "THERE IS NO Ami Bhatt IN SET FOR A4303202598\n"
     ]
    }
   ],
   "source": [
    "def testingNames(names, variables):\n",
    "    finished = {}\n",
    "    for i in names:\n",
    "        finished[i] = finalMerge(i, variables)\n",
    "    return finished\n",
    "testingNames([\"Ami Bhatt\", \"Martin Burke\", \"Lauren Byers\", \"Julie Bynum\", \"Peter Byers\"], [\"institution\", \"coauthor\",\"concept\"])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6756a7be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
