{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72ba35bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/FionaXu/Documents/Research/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning:\n",
      "\n",
      "urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm as progress\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from plotly.offline import plot\n",
    "import dimcli\n",
    "from dimcli.utils import *\n",
    "import os, sys, time, json\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "import csv\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e9dc751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==\n",
      "Logging in..\n",
      "\u001b[2mDimcli - Dimensions API Client (v1.4)\u001b[0m\n",
      "\u001b[2mConnected to: <https://app.dimensions.ai/api/dsl> - DSL v2.10\u001b[0m\n",
      "\u001b[2mMethod: manual login\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Log into Dimensions\n",
    "#API key is: 9F8D648F0D7E437CB1736BEBDF007F02\n",
    "#!pip install dimcli -U --quiet \n",
    "\n",
    "print(\"==\\nLogging in..\")\n",
    "# https://digital-science.github.io/dimcli/getting-started.html#authentication\n",
    "ENDPOINT = \"https://app.dimensions.ai\"\n",
    "if 'google.colab' in sys.modules:\n",
    "    import getpass\n",
    "    dimcli.login(key=KEY, endpoint=ENDPOINT)\n",
    "else:\n",
    "    KEY = \"9F8D648F0D7E437CB1736BEBDF007F02\"\n",
    "    dimcli.login(key=KEY, endpoint=ENDPOINT)\n",
    "dsl = dimcli.Dsl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4da5138f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '\\\\Users\\\\ashle\\\\OneDrive\\\\School\\\\Capstone\\\\names\\\\original_names.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m     22\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mashle\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSchool\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCapstone\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124moriginal_names.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 23\u001b[0m all_names \u001b[38;5;241m=\u001b[39m \u001b[43mread_names_from_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m all_names \u001b[38;5;241m=\u001b[39m all_names[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Now you can use the lists first_names and last_names as needed\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m, in \u001b[0;36mread_names_from_csv\u001b[0;34m(file_path, encoding)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread_names_from_csv\u001b[39m(file_path, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      3\u001b[0m     all_names \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mignore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m csv_file:\n\u001b[1;32m      6\u001b[0m         csv_reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(csv_file)\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;66;03m# Assuming the first column contains first names and the second column contains last names\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Research/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '\\\\Users\\\\ashle\\\\OneDrive\\\\School\\\\Capstone\\\\names\\\\original_names.csv'"
     ]
    }
   ],
   "source": [
    "#RUN ONLY IF YOUR NAMES ARE IN A CSV, IF NOT MOVE TO NEXT CELL\n",
    "def read_names_from_csv(file_path, encoding='utf-8'):\n",
    "    all_names = []\n",
    "\n",
    "    with open(file_path, 'r', encoding=encoding, errors='ignore') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        \n",
    "        # Assuming the first column contains first names and the second column contains last names\n",
    "        for row in csv_reader:\n",
    "            try:\n",
    "                if len(row) >= 2:  # Ensure the row has at least two columns\n",
    "                    first_names = row[1]\n",
    "                    last_names = row[3]\n",
    "                    full_name = first_names + \" \" + last_names\n",
    "                    all_names.append(full_name)\n",
    "            except  UnicodeDecodeError as e:\n",
    "                print(f\"Error decoding line {csv_reader.line_num}: {e}\")\n",
    "\n",
    "    return all_names\n",
    "\n",
    "# Example usage\n",
    "file_path = r'150physicianscientists.csv'\n",
    "all_names = read_names_from_csv(file_path)\n",
    "all_names = all_names[1:]\n",
    "\n",
    "# Now you can use the lists first_names and last_names as needed\n",
    "print(f'ALL NAMES({len(all_names)}) :')\n",
    "print(\"======================================================\")\n",
    "print(all_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4973cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN CELL IF YOUR NAMES ARE IN A LIST\n",
    "#put your list of names here\n",
    "all_names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07bbdbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n",
      "0-18 / 18 (0.70s)\u001b[0m\n",
      "===\n",
      "Records extracted: 18\u001b[0m\n",
      "Starting iteration with limit=1000 skip=0 ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 18 unique ids for Leslie Schoenfield \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0-18 / 18 (2.30s)\u001b[0m\n",
      "===\n",
      "Records extracted: 18\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++ FINAL 2 Working ID(s) +++++++++++\n",
      "{'ur.0102031123.62', 'ur.014424615212.32'}\n"
     ]
    }
   ],
   "source": [
    "#gets research id for a name\n",
    "def researcherIds(name):\n",
    "    res = dsl.query_iterative(f\"\"\"search researchers for \"{name}\" return researchers\"\"\")\n",
    "    listDict = res.json['researchers']\n",
    "    allIds = set()\n",
    "    for idv in listDict:\n",
    "        allIds.add(idv['id'])\n",
    "\n",
    "    allIds = list(allIds)  # Convert set back to a list if needed\n",
    "    \n",
    "    if len(allIds) > 512:    \n",
    "        allIds = allIds[0:512]\n",
    "    print(f'Total of {len(allIds)} unique ids for {name} ')\n",
    "\n",
    "    # Constructing the DSL query with the list of IDs\n",
    "    query_ids = ', '.join([f'\"{id_val}\"' for id_val in allIds])\n",
    "    query = f'search researchers where id in [{query_ids}] return researchers[id+obsolete+redirect]'\n",
    "\n",
    "    # Execute the DSL query\n",
    "    res2 = dsl.query_iterative(query)\n",
    "    listDict2 = res2.json['researchers']\n",
    "    allWorkingIDs = set()\n",
    "    for person in listDict2:\n",
    "        if person['obsolete'] == 0:  # Current Working Id(s)\n",
    "            allWorkingIDs.add(person[\"id\"])\n",
    "        else:\n",
    "            for ids in person['redirect']:\n",
    "                allWorkingIDs.add(ids)\n",
    "    \n",
    "    print(f'++++++++ FINAL {len(allWorkingIDs)} Working ID(s) +++++++++++')  \n",
    "    print(allWorkingIDs)\n",
    "    \n",
    "    return allWorkingIDs\n",
    "testIDs = researcherIds(\"Leslie Schoenfield\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc317488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allIds(namesList):\n",
    "    finalNames = {} \n",
    "    secondNames = {}\n",
    "    zeroNames = {}\n",
    "    count = 0\n",
    "\n",
    "    for name in namesList:\n",
    "        try:\n",
    "            validIds = researcherIds(name)\n",
    "\n",
    "            if len(validIds) == 0:\n",
    "                zeroNames[name] = set()\n",
    "                finalNames[name] = set()\n",
    "                pass\n",
    "            elif len(validIds) == 1:\n",
    "                count += 1\n",
    "                print(name, count)\n",
    "                finalNames[name] = validIds\n",
    "            elif len(validIds) == 2:\n",
    "                secondNames[name] = validIds\n",
    "                finalNames[name] = validIds\n",
    "            else:\n",
    "                finalNames[name] = validIds\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred for {name}: {e}\")\n",
    "    return finalNames, secondNames, zeroNames\n",
    "        \n",
    "resultAll, pairsAll, zeroNames = allIds(all_names)\n",
    "#resultAll is all names with more than two ids\n",
    "#pairsAll is all names with two ids\n",
    "#zeroNames is all names with no ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be67287",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this writes only names with more than two ids to file\n",
    "print(len(resultAll))\n",
    "print(len(pairsAll))\n",
    "print(len(zeroNames))\n",
    "\n",
    "def write_set_to_csv(file_path, my_set):\n",
    "    with open(file_path, 'w', newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "\n",
    "        # Write the header\n",
    "        writer.writerow(['Name', 'ID'])\n",
    "\n",
    "        # Write the data\n",
    "        for name, id_set in my_set.items():                \n",
    "            id_set = list(id_set)\n",
    "            writer.writerow([name, id_set])\n",
    "            \n",
    "write_set_to_csv(\"dimensionsAI_NameIds.csv\", resultAll)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8604461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you want to write all you names to a csv file\n",
    "merged_dict = {resultAll, pairsAll, zeroNames}\n",
    "write_set_to_csv(\"dimensionsAI_NameIds.csv\", merged_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
